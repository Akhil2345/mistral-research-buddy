# ğŸš€ Local AI Research Assistant â€” Offline, Private & Smart ğŸ›¡ï¸ğŸ§‘â€ğŸ’»

Your personal offline AI research team powered by âœ¨ **LangChain** + ğŸ¦™ **Mistral via Ollama**.  
Run intelligent agents that analyze, search, summarize, and synthesize â€” all 100% locally.

> ğŸ Think of it like having your own **AI research lab** on your laptop â€” no API keys, no cloud, no limits.

---

## ğŸŒŸ Project Goals

ğŸ¯ Build a **Multi-Agent Local AI Research Assistant** with:

- ğŸ§© Framework: `LangChain`  
- ğŸ¦™ LLM: Local `Mistral` via Ollama  
- ğŸ¤– Agents:  
  ğŸ” `Analyzer` â†’ ğŸŒ `Searcher` â†’ âœ‚ï¸ `Summarizer` â†’ ğŸ§  `Synthesizer`

---

## ğŸ“‚ Folder Structure

```bash
local_ai_searcher/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ analyzer.py
â”‚   â”œâ”€â”€ searcher.py
â”‚   â”œâ”€â”€ summarizer.py
â”‚   â””â”€â”€ synthesizer.py
â”œâ”€â”€ main.py
â”œâ”€â”€ llm.py
â””â”€â”€ requirements.txt


git clone https://github.com/yourusername/local_ai_searcher.git
cd local_ai_searcher
